Here's a subtle one that turned out to be crucial for Gemini. Models would escape characters inside the XML tags - turning quotes into HTML entities or adding backslashes. The fuzzy matcher obviously couldn't find the escaped version in the actual buffer. Even worse with newlines - models would send literal backslash-n instead of actual newlines. This was killing Gemini's performance - only 35% pass rate! One line in the prompt - 'Do not escape characters within tags' - had a massive impact. Gemini went from 35% to 86%, Claude improved from 96% to 98%, and GPT-4 hit 100%. Sometimes the simplest instructions fix the biggest problems, especially when you discover a model's specific quirk.